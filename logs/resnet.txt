torch version: 2.9.0+cu126
cuda available: True
gpu name: NVIDIA GeForce GTX 1650
Using device: cuda:0

=== Training with lr=0.001, weight_decay=0.0, batch_size=16 ===
lr=0.001, wd=0.0, bs=16 | Epoch 1/5 | Loss: 0.0927 | F1: 0.9984 (P: 1.0000, R: 0.9967)
lr=0.001, wd=0.0, bs=16 | Epoch 2/5 | Loss: 0.0171 | F1: 0.9993 (P: 1.0000, R: 0.9987)
lr=0.001, wd=0.0, bs=16 | Epoch 3/5 | Loss: 0.0058 | F1: 0.9987 (P: 1.0000, R: 0.9974)
lr=0.001, wd=0.0, bs=16 | Epoch 4/5 | Loss: 0.0082 | F1: 0.9993 (P: 0.9993, R: 0.9993)
lr=0.001, wd=0.0, bs=16 | Epoch 5/5 | Loss: 0.0052 | F1: 1.0000 (P: 1.0000, R: 1.0000)

=== Training with lr=0.001, weight_decay=0.0, batch_size=32 ===
lr=0.001, wd=0.0, bs=32 | Epoch 1/5 | Loss: 0.0935 | F1: 0.9967 (P: 0.9980, R: 0.9954)
lr=0.001, wd=0.0, bs=32 | Epoch 2/5 | Loss: 0.0179 | F1: 0.9993 (P: 1.0000, R: 0.9987)
lr=0.001, wd=0.0, bs=32 | Epoch 3/5 | Loss: 0.0073 | F1: 0.9987 (P: 0.9993, R: 0.9980)
lr=0.001, wd=0.0, bs=32 | Epoch 4/5 | Loss: 0.0067 | F1: 1.0000 (P: 1.0000, R: 1.0000)
lr=0.001, wd=0.0, bs=32 | Epoch 5/5 | Loss: 0.0038 | F1: 1.0000 (P: 1.0000, R: 1.0000)

=== Training with lr=0.001, weight_decay=0.0, batch_size=64 ===
lr=0.001, wd=0.0, bs=64 | Epoch 1/5 | Loss: 0.1315 | F1: 0.9925 (P: 0.9961, R: 0.9889)
lr=0.001, wd=0.0, bs=64 | Epoch 2/5 | Loss: 0.0268 | F1: 0.9954 (P: 0.9980, R: 0.9928)
lr=0.001, wd=0.0, bs=64 | Epoch 3/5 | Loss: 0.0127 | F1: 0.9974 (P: 0.9987, R: 0.9961)
lr=0.001, wd=0.0, bs=64 | Epoch 4/5 | Loss: 0.0082 | F1: 0.9990 (P: 0.9993, R: 0.9987)
lr=0.001, wd=0.0, bs=64 | Epoch 5/5 | Loss: 0.0054 | F1: 0.9993 (P: 0.9993, R: 0.9993)

=== Training with lr=0.001, weight_decay=0.0001, batch_size=16 ===
lr=0.001, wd=0.0001, bs=16 | Epoch 1/5 | Loss: 0.0874 | F1: 0.9984 (P: 0.9987, R: 0.9980)
lr=0.001, wd=0.0001, bs=16 | Epoch 2/5 | Loss: 0.0174 | F1: 0.9993 (P: 0.9993, R: 0.9993)
lr=0.001, wd=0.0001, bs=16 | Epoch 3/5 | Loss: 0.0143 | F1: 1.0000 (P: 1.0000, R: 1.0000)
lr=0.001, wd=0.0001, bs=16 | Epoch 4/5 | Loss: 0.0071 | F1: 1.0000 (P: 1.0000, R: 1.0000)
lr=0.001, wd=0.0001, bs=16 | Epoch 5/5 | Loss: 0.0049 | F1: 1.0000 (P: 1.0000, R: 1.0000)

=== Training with lr=0.001, weight_decay=0.0001, batch_size=32 ===
lr=0.001, wd=0.0001, bs=32 | Epoch 1/5 | Loss: 0.0930 | F1: 0.9980 (P: 0.9980, R: 0.9980)
lr=0.001, wd=0.0001, bs=32 | Epoch 2/5 | Loss: 0.0179 | F1: 0.9977 (P: 0.9993, R: 0.9961)
lr=0.001, wd=0.0001, bs=32 | Epoch 3/5 | Loss: 0.0100 | F1: 0.9984 (P: 1.0000, R: 0.9967)
lr=0.001, wd=0.0001, bs=32 | Epoch 4/5 | Loss: 0.0074 | F1: 1.0000 (P: 1.0000, R: 1.0000)
lr=0.001, wd=0.0001, bs=32 | Epoch 5/5 | Loss: 0.0044 | F1: 1.0000 (P: 1.0000, R: 1.0000)

=== Training with lr=0.001, weight_decay=0.0001, batch_size=64 ===
lr=0.001, wd=0.0001, bs=64 | Epoch 1/5 | Loss: 0.1269 | F1: 0.9928 (P: 0.9941, R: 0.9915)
lr=0.001, wd=0.0001, bs=64 | Epoch 2/5 | Loss: 0.0279 | F1: 0.9974 (P: 0.9961, R: 0.9987)
lr=0.001, wd=0.0001, bs=64 | Epoch 3/5 | Loss: 0.0114 | F1: 0.9984 (P: 1.0000, R: 0.9967)
lr=0.001, wd=0.0001, bs=64 | Epoch 4/5 | Loss: 0.0076 | F1: 0.9997 (P: 1.0000, R: 0.9993)
lr=0.001, wd=0.0001, bs=64 | Epoch 5/5 | Loss: 0.0052 | F1: 0.9990 (P: 1.0000, R: 0.9980)

=== Training with lr=0.001, weight_decay=0.001, batch_size=16 ===
lr=0.001, wd=0.001, bs=16 | Epoch 1/5 | Loss: 0.0874 | F1: 0.9964 (P: 0.9993, R: 0.9935)
lr=0.001, wd=0.001, bs=16 | Epoch 2/5 | Loss: 0.0227 | F1: 0.9974 (P: 1.0000, R: 0.9948)
lr=0.001, wd=0.001, bs=16 | Epoch 3/5 | Loss: 0.0105 | F1: 0.9987 (P: 1.0000, R: 0.9974)
lr=0.001, wd=0.001, bs=16 | Epoch 4/5 | Loss: 0.0081 | F1: 0.9990 (P: 1.0000, R: 0.9980)
lr=0.001, wd=0.001, bs=16 | Epoch 5/5 | Loss: 0.0061 | F1: 0.9977 (P: 1.0000, R: 0.9954)

=== Training with lr=0.001, weight_decay=0.001, batch_size=32 ===
lr=0.001, wd=0.001, bs=32 | Epoch 1/5 | Loss: 0.0923 | F1: 0.9958 (P: 0.9980, R: 0.9935)
lr=0.001, wd=0.001, bs=32 | Epoch 2/5 | Loss: 0.0174 | F1: 0.9980 (P: 0.9993, R: 0.9967)
lr=0.001, wd=0.001, bs=32 | Epoch 3/5 | Loss: 0.0079 | F1: 0.9993 (P: 1.0000, R: 0.9987)
lr=0.001, wd=0.001, bs=32 | Epoch 4/5 | Loss: 0.0045 | F1: 0.9993 (P: 1.0000, R: 0.9987)
lr=0.001, wd=0.001, bs=32 | Epoch 5/5 | Loss: 0.0031 | F1: 0.9993 (P: 1.0000, R: 0.9987)

=== Training with lr=0.001, weight_decay=0.001, batch_size=64 ===
lr=0.001, wd=0.001, bs=64 | Epoch 1/5 | Loss: 0.1271 | F1: 0.9935 (P: 0.9941, R: 0.9928)
lr=0.001, wd=0.001, bs=64 | Epoch 2/5 | Loss: 0.0271 | F1: 0.9967 (P: 0.9987, R: 0.9948)
lr=0.001, wd=0.001, bs=64 | Epoch 3/5 | Loss: 0.0130 | F1: 0.9984 (P: 0.9993, R: 0.9974)
lr=0.001, wd=0.001, bs=64 | Epoch 4/5 | Loss: 0.0082 | F1: 0.9990 (P: 0.9993, R: 0.9987)
lr=0.001, wd=0.001, bs=64 | Epoch 5/5 | Loss: 0.0048 | F1: 0.9990 (P: 0.9993, R: 0.9987)

=== Training with lr=0.0003, weight_decay=0.0, batch_size=16 ===
lr=0.0003, wd=0.0, bs=16 | Epoch 1/5 | Loss: 0.1384 | F1: 0.9915 (P: 0.9948, R: 0.9883)
lr=0.0003, wd=0.0, bs=16 | Epoch 2/5 | Loss: 0.0439 | F1: 0.9958 (P: 0.9961, R: 0.9954)
lr=0.0003, wd=0.0, bs=16 | Epoch 3/5 | Loss: 0.0238 | F1: 0.9974 (P: 0.9993, R: 0.9954)
lr=0.0003, wd=0.0, bs=16 | Epoch 4/5 | Loss: 0.0211 | F1: 0.9974 (P: 0.9993, R: 0.9954)
lr=0.0003, wd=0.0, bs=16 | Epoch 5/5 | Loss: 0.0143 | F1: 0.9971 (P: 1.0000, R: 0.9941)

=== Training with lr=0.0003, weight_decay=0.0, batch_size=32 ===
lr=0.0003, wd=0.0, bs=32 | Epoch 1/5 | Loss: 0.1748 | F1: 0.9872 (P: 0.9954, R: 0.9791)
lr=0.0003, wd=0.0, bs=32 | Epoch 2/5 | Loss: 0.0529 | F1: 0.9941 (P: 0.9967, R: 0.9915)
lr=0.0003, wd=0.0, bs=32 | Epoch 3/5 | Loss: 0.0330 | F1: 0.9954 (P: 0.9967, R: 0.9941)
lr=0.0003, wd=0.0, bs=32 | Epoch 4/5 | Loss: 0.0257 | F1: 0.9951 (P: 0.9987, R: 0.9915)
lr=0.0003, wd=0.0, bs=32 | Epoch 5/5 | Loss: 0.0161 | F1: 0.9971 (P: 0.9987, R: 0.9954)

=== Training with lr=0.0003, weight_decay=0.0, batch_size=64 ===
lr=0.0003, wd=0.0, bs=64 | Epoch 1/5 | Loss: 0.2342 | F1: 0.9816 (P: 0.9907, R: 0.9726)
lr=0.0003, wd=0.0, bs=64 | Epoch 2/5 | Loss: 0.0783 | F1: 0.9882 (P: 0.9934, R: 0.9831)
lr=0.0003, wd=0.0, bs=64 | Epoch 3/5 | Loss: 0.0477 | F1: 0.9922 (P: 0.9935, R: 0.9909)
lr=0.0003, wd=0.0, bs=64 | Epoch 4/5 | Loss: 0.0335 | F1: 0.9938 (P: 0.9974, R: 0.9902)
lr=0.0003, wd=0.0, bs=64 | Epoch 5/5 | Loss: 0.0259 | F1: 0.9958 (P: 0.9974, R: 0.9941)

=== Training with lr=0.0003, weight_decay=0.0001, batch_size=16 ===
lr=0.0003, wd=0.0001, bs=16 | Epoch 1/5 | Loss: 0.1367 | F1: 0.9875 (P: 0.9967, R: 0.9785)
lr=0.0003, wd=0.0001, bs=16 | Epoch 2/5 | Loss: 0.0465 | F1: 0.9944 (P: 0.9980, R: 0.9909)
lr=0.0003, wd=0.0001, bs=16 | Epoch 3/5 | Loss: 0.0292 | F1: 0.9967 (P: 0.9993, R: 0.9941)
lr=0.0003, wd=0.0001, bs=16 | Epoch 4/5 | Loss: 0.0190 | F1: 0.9961 (P: 0.9993, R: 0.9928)
lr=0.0003, wd=0.0001, bs=16 | Epoch 5/5 | Loss: 0.0122 | F1: 0.9990 (P: 0.9993, R: 0.9987)

=== Training with lr=0.0003, weight_decay=0.0001, batch_size=32 ===
lr=0.0003, wd=0.0001, bs=32 | Epoch 1/5 | Loss: 0.1608 | F1: 0.9869 (P: 0.9927, R: 0.9811)
lr=0.0003, wd=0.0001, bs=32 | Epoch 2/5 | Loss: 0.0550 | F1: 0.9945 (P: 0.9954, R: 0.9935)
lr=0.0003, wd=0.0001, bs=32 | Epoch 3/5 | Loss: 0.0320 | F1: 0.9951 (P: 0.9980, R: 0.9922)
lr=0.0003, wd=0.0001, bs=32 | Epoch 4/5 | Loss: 0.0231 | F1: 0.9974 (P: 0.9987, R: 0.9961)
lr=0.0003, wd=0.0001, bs=32 | Epoch 5/5 | Loss: 0.0162 | F1: 0.9977 (P: 0.9993, R: 0.9961)

=== Training with lr=0.0003, weight_decay=0.0001, batch_size=64 ===
lr=0.0003, wd=0.0001, bs=64 | Epoch 1/5 | Loss: 0.2328 | F1: 0.9812 (P: 0.9914, R: 0.9713)
lr=0.0003, wd=0.0001, bs=64 | Epoch 2/5 | Loss: 0.0776 | F1: 0.9892 (P: 0.9934, R: 0.9850)
lr=0.0003, wd=0.0001, bs=64 | Epoch 3/5 | Loss: 0.0493 | F1: 0.9922 (P: 0.9948, R: 0.9896)
lr=0.0003, wd=0.0001, bs=64 | Epoch 4/5 | Loss: 0.0334 | F1: 0.9945 (P: 0.9948, R: 0.9941)
lr=0.0003, wd=0.0001, bs=64 | Epoch 5/5 | Loss: 0.0258 | F1: 0.9958 (P: 0.9954, R: 0.9961)

=== Training with lr=0.0003, weight_decay=0.001, batch_size=16 ===
lr=0.0003, wd=0.001, bs=16 | Epoch 1/5 | Loss: 0.1369 | F1: 0.9898 (P: 0.9967, R: 0.9831)
lr=0.0003, wd=0.001, bs=16 | Epoch 2/5 | Loss: 0.0508 | F1: 0.9964 (P: 0.9967, R: 0.9961)
lr=0.0003, wd=0.001, bs=16 | Epoch 3/5 | Loss: 0.0300 | F1: 0.9993 (P: 1.0000, R: 0.9987)
lr=0.0003, wd=0.001, bs=16 | Epoch 4/5 | Loss: 0.0182 | F1: 0.9993 (P: 1.0000, R: 0.9987)
lr=0.0003, wd=0.001, bs=16 | Epoch 5/5 | Loss: 0.0121 | F1: 0.9977 (P: 1.0000, R: 0.9954)

=== Training with lr=0.0003, weight_decay=0.001, batch_size=32 ===
lr=0.0003, wd=0.001, bs=32 | Epoch 1/5 | Loss: 0.1792 | F1: 0.9825 (P: 0.9960, R: 0.9694)
lr=0.0003, wd=0.001, bs=32 | Epoch 2/5 | Loss: 0.0569 | F1: 0.9928 (P: 0.9941, R: 0.9915)
lr=0.0003, wd=0.001, bs=32 | Epoch 3/5 | Loss: 0.0328 | F1: 0.9974 (P: 0.9980, R: 0.9967)
lr=0.0003, wd=0.001, bs=32 | Epoch 4/5 | Loss: 0.0238 | F1: 0.9974 (P: 0.9987, R: 0.9961)
lr=0.0003, wd=0.001, bs=32 | Epoch 5/5 | Loss: 0.0160 | F1: 0.9977 (P: 0.9980, R: 0.9974)

=== Training with lr=0.0003, weight_decay=0.001, batch_size=64 ===
lr=0.0003, wd=0.001, bs=64 | Epoch 1/5 | Loss: 0.2404 | F1: 0.9804 (P: 0.9849, R: 0.9759)
lr=0.0003, wd=0.001, bs=64 | Epoch 2/5 | Loss: 0.0748 | F1: 0.9839 (P: 0.9947, R: 0.9733)
lr=0.0003, wd=0.001, bs=64 | Epoch 3/5 | Loss: 0.0504 | F1: 0.9938 (P: 0.9948, R: 0.9928)
lr=0.0003, wd=0.001, bs=64 | Epoch 4/5 | Loss: 0.0363 | F1: 0.9951 (P: 0.9954, R: 0.9948)
lr=0.0003, wd=0.001, bs=64 | Epoch 5/5 | Loss: 0.0264 | F1: 0.9944 (P: 0.9961, R: 0.9928)

=== Training with lr=0.0001, weight_decay=0.0, batch_size=16 ===
lr=0.0001, wd=0.0, bs=16 | Epoch 1/5 | Loss: 0.2147 | F1: 0.9788 (P: 0.9953, R: 0.9628)
lr=0.0001, wd=0.0, bs=16 | Epoch 2/5 | Loss: 0.0969 | F1: 0.9878 (P: 0.9954, R: 0.9804)
lr=0.0001, wd=0.0, bs=16 | Epoch 3/5 | Loss: 0.0663 | F1: 0.9908 (P: 0.9960, R: 0.9857)
lr=0.0001, wd=0.0, bs=16 | Epoch 4/5 | Loss: 0.0466 | F1: 0.9944 (P: 0.9961, R: 0.9928)
lr=0.0001, wd=0.0, bs=16 | Epoch 5/5 | Loss: 0.0420 | F1: 0.9958 (P: 0.9974, R: 0.9941)

=== Training with lr=0.0001, weight_decay=0.0, batch_size=32 ===
lr=0.0001, wd=0.0, bs=32 | Epoch 1/5 | Loss: 0.2777 | F1: 0.9758 (P: 0.9809, R: 0.9707)
lr=0.0001, wd=0.0, bs=32 | Epoch 2/5 | Loss: 0.1096 | F1: 0.9815 (P: 0.9933, R: 0.9700)
lr=0.0001, wd=0.0, bs=32 | Epoch 3/5 | Loss: 0.0796 | F1: 0.9915 (P: 0.9935, R: 0.9896)
lr=0.0001, wd=0.0, bs=32 | Epoch 4/5 | Loss: 0.0634 | F1: 0.9918 (P: 0.9948, R: 0.9889)
lr=0.0001, wd=0.0, bs=32 | Epoch 5/5 | Loss: 0.0530 | F1: 0.9922 (P: 0.9954, R: 0.9889)

=== Training with lr=0.0001, weight_decay=0.0, batch_size=64 ===
lr=0.0001, wd=0.0, bs=64 | Epoch 1/5 | Loss: 0.3702 | F1: 0.9654 (P: 0.9767, R: 0.9544)
lr=0.0001, wd=0.0, bs=64 | Epoch 2/5 | Loss: 0.1597 | F1: 0.9769 (P: 0.9765, R: 0.9772)
lr=0.0001, wd=0.0, bs=64 | Epoch 3/5 | Loss: 0.1118 | F1: 0.9809 (P: 0.9894, R: 0.9726)
lr=0.0001, wd=0.0, bs=64 | Epoch 4/5 | Loss: 0.0890 | F1: 0.9846 (P: 0.9901, R: 0.9791)
lr=0.0001, wd=0.0, bs=64 | Epoch 5/5 | Loss: 0.0698 | F1: 0.9866 (P: 0.9914, R: 0.9817)

=== Training with lr=0.0001, weight_decay=0.0001, batch_size=16 ===
lr=0.0001, wd=0.0001, bs=16 | Epoch 1/5 | Loss: 0.2242 | F1: 0.9809 (P: 0.9933, R: 0.9687)
lr=0.0001, wd=0.0001, bs=16 | Epoch 2/5 | Loss: 0.0970 | F1: 0.9899 (P: 0.9941, R: 0.9857)
lr=0.0001, wd=0.0001, bs=16 | Epoch 3/5 | Loss: 0.0721 | F1: 0.9918 (P: 0.9961, R: 0.9876)
lr=0.0001, wd=0.0001, bs=16 | Epoch 4/5 | Loss: 0.0515 | F1: 0.9951 (P: 0.9967, R: 0.9935)
lr=0.0001, wd=0.0001, bs=16 | Epoch 5/5 | Loss: 0.0440 | F1: 0.9961 (P: 0.9980, R: 0.9941)

=== Training with lr=0.0001, weight_decay=0.0001, batch_size=32 ===
lr=0.0001, wd=0.0001, bs=32 | Epoch 1/5 | Loss: 0.2967 | F1: 0.9720 (P: 0.9808, R: 0.9635)
lr=0.0001, wd=0.0001, bs=32 | Epoch 2/5 | Loss: 0.1211 | F1: 0.9823 (P: 0.9881, R: 0.9765)
lr=0.0001, wd=0.0001, bs=32 | Epoch 3/5 | Loss: 0.0834 | F1: 0.9866 (P: 0.9902, R: 0.9831)
lr=0.0001, wd=0.0001, bs=32 | Epoch 4/5 | Loss: 0.0686 | F1: 0.9902 (P: 0.9947, R: 0.9857)
lr=0.0001, wd=0.0001, bs=32 | Epoch 5/5 | Loss: 0.0513 | F1: 0.9918 (P: 0.9954, R: 0.9883)

=== Training with lr=0.0001, weight_decay=0.0001, batch_size=64 ===
lr=0.0001, wd=0.0001, bs=64 | Epoch 1/5 | Loss: 0.3686 | F1: 0.9589 (P: 0.9607, R: 0.9570)
lr=0.0001, wd=0.0001, bs=64 | Epoch 2/5 | Loss: 0.1646 | F1: 0.9707 (P: 0.9820, R: 0.9596)
lr=0.0001, wd=0.0001, bs=64 | Epoch 3/5 | Loss: 0.1175 | F1: 0.9776 (P: 0.9874, R: 0.9681)
lr=0.0001, wd=0.0001, bs=64 | Epoch 4/5 | Loss: 0.0909 | F1: 0.9847 (P: 0.9863, R: 0.9831)
lr=0.0001, wd=0.0001, bs=64 | Epoch 5/5 | Loss: 0.0766 | F1: 0.9869 (P: 0.9889, R: 0.9850)

=== Training with lr=0.0001, weight_decay=0.001, batch_size=16 ===
lr=0.0001, wd=0.001, bs=16 | Epoch 1/5 | Loss: 0.2308 | F1: 0.9826 (P: 0.9894, R: 0.9759)
lr=0.0001, wd=0.001, bs=16 | Epoch 2/5 | Loss: 0.0994 | F1: 0.9869 (P: 0.9954, R: 0.9785)
lr=0.0001, wd=0.001, bs=16 | Epoch 3/5 | Loss: 0.0681 | F1: 0.9928 (P: 0.9961, R: 0.9896)
lr=0.0001, wd=0.001, bs=16 | Epoch 4/5 | Loss: 0.0547 | F1: 0.9931 (P: 0.9980, R: 0.9883)
lr=0.0001, wd=0.001, bs=16 | Epoch 5/5 | Loss: 0.0386 | F1: 0.9951 (P: 0.9987, R: 0.9915)

=== Training with lr=0.0001, weight_decay=0.001, batch_size=32 ===
lr=0.0001, wd=0.001, bs=32 | Epoch 1/5 | Loss: 0.2676 | F1: 0.9708 (P: 0.9892, R: 0.9531)
lr=0.0001, wd=0.001, bs=32 | Epoch 2/5 | Loss: 0.1120 | F1: 0.9809 (P: 0.9920, R: 0.9700)
lr=0.0001, wd=0.001, bs=32 | Epoch 3/5 | Loss: 0.0822 | F1: 0.9875 (P: 0.9947, R: 0.9804)
lr=0.0001, wd=0.001, bs=32 | Epoch 4/5 | Loss: 0.0661 | F1: 0.9892 (P: 0.9960, R: 0.9824)
lr=0.0001, wd=0.001, bs=32 | Epoch 5/5 | Loss: 0.0499 | F1: 0.9928 (P: 0.9954, R: 0.9902)

=== Training with lr=0.0001, weight_decay=0.001, batch_size=64 ===
lr=0.0001, wd=0.001, bs=64 | Epoch 1/5 | Loss: 0.3660 | F1: 0.9624 (P: 0.9733, R: 0.9518)
lr=0.0001, wd=0.001, bs=64 | Epoch 2/5 | Loss: 0.1598 | F1: 0.9747 (P: 0.9815, R: 0.9681)
lr=0.0001, wd=0.001, bs=64 | Epoch 3/5 | Loss: 0.1129 | F1: 0.9786 (P: 0.9874, R: 0.9700)
lr=0.0001, wd=0.001, bs=64 | Epoch 4/5 | Loss: 0.0911 | F1: 0.9819 (P: 0.9888, R: 0.9752)
lr=0.0001, wd=0.001, bs=64 | Epoch 5/5 | Loss: 0.0754 | F1: 0.9829 (P: 0.9894, R: 0.9765)

=== Best configuration ===
{'lr': 0.001, 'weight_decay': 0.0, 'batch_size': 16, 'epoch': 5}
Best F1: 1.0000
Saved best model to: results/resnet_best_grid.pt